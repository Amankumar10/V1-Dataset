{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb35db06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmpatheticDialogues loaded:\n",
      "Shape: (76673, 8)\n",
      "Columns: ['conv_id', 'utterance_idx', 'context', 'prompt', 'speaker_idx', 'utterance', 'selfeval', 'tags']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>utterance</th>\n",
       "      <th>selfeval</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>1</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>1</td>\n",
       "      <td>I remember going to see the fireworks with my ...</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>2</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>0</td>\n",
       "      <td>Was this a friend you were in love with_comma_...</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>3</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>1</td>\n",
       "      <td>This was a best friend. I miss her.</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        conv_id utterance_idx      context  \\\n",
       "0  hit:0_conv:1             1  sentimental   \n",
       "1  hit:0_conv:1             2  sentimental   \n",
       "2  hit:0_conv:1             3  sentimental   \n",
       "\n",
       "                                              prompt speaker_idx  \\\n",
       "0  I remember going to the fireworks with my best...           1   \n",
       "1  I remember going to the fireworks with my best...           0   \n",
       "2  I remember going to the fireworks with my best...           1   \n",
       "\n",
       "                                           utterance     selfeval tags  \n",
       "0  I remember going to see the fireworks with my ...  5|5|5_2|2|5       \n",
       "1  Was this a friend you were in love with_comma_...  5|5|5_2|2|5       \n",
       "2                This was a best friend. I miss her.  5|5|5_2|2|5       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 58829 empathetic pairs so far.\n",
      "\n",
      "GoEmotions loaded:\n",
      "Shape: (211225, 38)\n",
      "Columns: ['text', 'id', 'author', 'subreddit', 'link_id', 'parent_id', 'created_utc', 'rater_id', 'example_very_unclear', 'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral', 'clean_text']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>example_very_unclear</th>\n",
       "      <th>admiration</th>\n",
       "      <th>...</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>eew5j0j</td>\n",
       "      <td>Brdd9</td>\n",
       "      <td>nrl</td>\n",
       "      <td>t3_ajis4z</td>\n",
       "      <td>t1_eew18eq</td>\n",
       "      <td>1548381039.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>that game hurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;sexuality shouldn’t be a grouping category I...</td>\n",
       "      <td>eemcysk</td>\n",
       "      <td>TheGreen888</td>\n",
       "      <td>unpopularopinion</td>\n",
       "      <td>t3_ai4q37</td>\n",
       "      <td>t3_ai4q37</td>\n",
       "      <td>1548084169.0</td>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sexuality shouldn t be a grouping category it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>ed2mah1</td>\n",
       "      <td>Labalool</td>\n",
       "      <td>confessions</td>\n",
       "      <td>t3_abru74</td>\n",
       "      <td>t1_ed2m7g7</td>\n",
       "      <td>1546427744.0</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>you do right if you don t care then fuck em</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       id       author  \\\n",
       "0                                    That game hurt.  eew5j0j        Brdd9   \n",
       "1   >sexuality shouldn’t be a grouping category I...  eemcysk  TheGreen888   \n",
       "2     You do right, if you don't care then fuck 'em!  ed2mah1     Labalool   \n",
       "\n",
       "          subreddit    link_id   parent_id   created_utc rater_id  \\\n",
       "0               nrl  t3_ajis4z  t1_eew18eq  1548381039.0        1   \n",
       "1  unpopularopinion  t3_ai4q37   t3_ai4q37  1548084169.0       37   \n",
       "2       confessions  t3_abru74  t1_ed2m7g7  1546427744.0       37   \n",
       "\n",
       "  example_very_unclear admiration  ... nervousness optimism pride realization  \\\n",
       "0                False          0  ...           0        0     0           0   \n",
       "1                 True          0  ...           0        0     0           0   \n",
       "2                False          0  ...           0        0     0           0   \n",
       "\n",
       "  relief remorse sadness surprise neutral  \\\n",
       "0      0       0       1        0       0   \n",
       "1      0       0       0        0       0   \n",
       "2      0       0       0        0       1   \n",
       "\n",
       "                                          clean_text  \n",
       "0                                     that game hurt  \n",
       "1  sexuality shouldn t be a grouping category it ...  \n",
       "2        you do right if you don t care then fuck em  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 211225 goemotions pairs so far.\n",
      "\n",
      "Persona dataset loaded:\n",
      "Shape: (8939, 3)\n",
      "Columns: ['Unnamed: 0', 'Persona', 'chat']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Persona</th>\n",
       "      <th>chat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>i like to remodel homes. i like to go hunting...</td>\n",
       "      <td>hi , how are you doing ? i am getting ready to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>my mom is my best friend. i have four sisters...</td>\n",
       "      <td>hi , how are you doing today ?\\ni am spending ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>i had a gig at local theater last night. i wo...</td>\n",
       "      <td>we all live in a yellow submarine , a yellow s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                            Persona  \\\n",
       "0          0   i like to remodel homes. i like to go hunting...   \n",
       "1          1   my mom is my best friend. i have four sisters...   \n",
       "2          2   i had a gig at local theater last night. i wo...   \n",
       "\n",
       "                                                chat  \n",
       "0  hi , how are you doing ? i am getting ready to...  \n",
       "1  hi , how are you doing today ?\\ni am spending ...  \n",
       "2  we all live in a yellow submarine , a yellow s...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using persona text column: chat\n",
      "Collected 210777 persona-derived pairs so far.\n",
      "\n",
      "Total raw samples collected: 480831\n",
      "After dedupe: 423139\n",
      "Wrote 423139 samples to compatika_combined.txt (size: 56.05 MB)\n",
      "Done. Sample output preview:\n",
      "USER: i am good , how about yourself ?\n",
      "COMPATIKA: I hear what you’re saying. What feeling comes up with it?\n",
      "\n",
      "USER: ooh nice .\n",
      "COMPATIKA: That seems important. What part stands out emotionally?\n",
      "\n",
      "USER: i was scared to walk home yesterday\n",
      "COMPATIKA: Why were you scared?\n",
      "\n",
      "USER: Remember the year “Song 2” was number 2? Good times.\n",
      "COMPATIKA: I’m listening—how is this affecting you today?\n",
      "\n",
      "USER: well that is america for you i am not a huge fan of the government either\n",
      "COMPATIKA: Thanks for opening up. What’s moving inside you as you say that?\n",
      "\n",
      "USER: i have a mini van .\n",
      "COMPATIKA: Thanks for telling me that. What’s the emotion behind it?\n",
      "\n",
      "USER: blue .\n",
      "COMPATIKA: That sounds meaningful. How does it feel for you internally?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combined dataset builder for Compatika V1\n",
    "# Supports: EmpatheticDialogues, GoEmotions, PersonaChat (CSV or JSONL)\n",
    "# Output: compatika_combined.txt (USER / COMPATIKA pairs)\n",
    "# Run in Jupyter. Edit dataset path variables below.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "# ========== CONFIG - set these paths ==========\n",
    "empathetic_path = r\"C:\\Users\\aman\\Desktop\\v1 dataset\\rawdata\\empathetic_dialogues\\train.csv\"   # or .jsonl\n",
    "goemotions_path = r\"C:\\Users\\aman\\Desktop\\v1 dataset\\rawdata\\goemotions_1\\goemotions_merged_clean.csv\"            # or .jsonl\n",
    "persona_path = r\"C:\\Users\\aman\\Desktop\\v1 dataset\\rawdata\\PersonaChat\\personality.csv\"                  # or .jsonl\n",
    "\n",
    "output_txt = \"compatika_combined.txt\"\n",
    "TARGET_SIZE_MB = None  # set to e.g. 40 to attempt ~40MB output, or None to just write all samples\n",
    "\n",
    "# ========== Templates / mappings ==========\n",
    "# Emotion -> templates (extend these lists to increase variety)\n",
    "TEMPLATES = TEMPLATES = {\n",
    "    \"sadness\": [\n",
    "        \"That sounds really painful. It’s okay to feel this way. Want to tell me what hurts most?\",\n",
    "        \"I’m sorry you’re feeling this. I’m here with you—what happened?\",\n",
    "        \"It makes sense that this feels heavy. What part is weighing on you the most?\",\n",
    "        \"That sadness sounds real. You deserve space to feel it. Want to share more?\",\n",
    "        \"It sounds like your heart is carrying a lot. What feels hardest right now?\",\n",
    "        \"I hear how much this affected you. What do you wish could have been different?\",\n",
    "        \"It’s understandable you’d feel sad about that. What’s underneath the sadness?\",\n",
    "        \"I’m here. Take your time—what emotion is coming up the strongest?\"\n",
    "    ],\n",
    "\n",
    "    \"anger\": [\n",
    "        \"It makes sense to feel angry about that. Want to share what set it off?\",\n",
    "        \"I hear your frustration. What part of this felt most unfair?\",\n",
    "        \"Your anger is valid. What boundary do you think was crossed?\",\n",
    "        \"It sounds like something really bothered you. What triggered it the most?\",\n",
    "        \"That reaction tells me something mattered to you. What was it?\",\n",
    "        \"I can feel the intensity there. Want to unpack the root of it together?\",\n",
    "        \"It’s okay to feel upset. What moment pushed you to that point?\",\n",
    "        \"That frustration sounds real. What do you wish they understood?\"\n",
    "    ],\n",
    "\n",
    "    \"anxiety\": [\n",
    "        \"Feeling anxious can be exhausting. What’s worrying you most right now?\",\n",
    "        \"It’s okay to feel nervous. Want to talk through what’s on your mind?\",\n",
    "        \"That tension sounds heavy. What thought keeps coming back?\",\n",
    "        \"You’re not alone—anxiety can feel overwhelming. What triggered it?\",\n",
    "        \"It makes sense your body reacted that way. What do you think it's trying to protect you from?\",\n",
    "        \"That sounds stressful. What’s the main fear underneath it?\",\n",
    "        \"I hear your worry. Want to sort through it gently step by step?\",\n",
    "        \"You’re carrying a lot of tension. What part feels the strongest?\"\n",
    "    ],\n",
    "\n",
    "    \"fear\": [\n",
    "        \"That sounds scary. I’m here with you—what feels most frightening?\",\n",
    "        \"It’s understandable to feel afraid. Want to share what’s worrying you?\",\n",
    "        \"That fear sounds real. What do you notice happening inside you?\",\n",
    "        \"You’re safe here. What part of this situation feels the most uncertain?\",\n",
    "        \"It makes sense you're scared—what do you think might happen?\",\n",
    "        \"That sounded like a fearful moment. Want to talk about it?\",\n",
    "        \"Fear can feel overwhelming. What triggered it for you?\",\n",
    "        \"You’re not alone in that feeling. What’s the fear pointing to?\"\n",
    "    ],\n",
    "\n",
    "    \"joy\": [\n",
    "        \"That’s wonderful to hear! What made the moment feel so good?\",\n",
    "        \"I’m glad you’re feeling joyful. Want to share more about it?\",\n",
    "        \"That’s such a warm moment. What stood out to you the most?\",\n",
    "        \"It sounds like something truly uplifting happened. What was it?\",\n",
    "        \"I can hear the happiness in your words. What sparked it?\",\n",
    "        \"That joy sounds genuine. What are you appreciating about it?\",\n",
    "        \"That feels like a bright spot. Want to savor it a bit more?\",\n",
    "        \"It’s lovely to hear something positive. What does it mean to you?\"\n",
    "    ],\n",
    "\n",
    "    \"love\": [\n",
    "        \"That’s a warm feeling. What does that person or experience mean to you?\",\n",
    "        \"It sounds meaningful to feel that way. Want to tell me more?\",\n",
    "        \"That affection seems deep. What do you value most about it?\",\n",
    "        \"That sounds like a heartfelt connection. How does it feel?\",\n",
    "        \"It’s a beautiful emotion. What brought it up for you?\",\n",
    "        \"I can feel the warmth in that. What does it bring out in you?\",\n",
    "        \"Love can carry many layers. What part is strongest for you?\",\n",
    "        \"It sounds like something very important to you. Want to share more?\"\n",
    "    ],\n",
    "\n",
    "    \"neutral\": [\n",
    "        \"Thanks for sharing that. How are you feeling about it right now?\",\n",
    "        \"I hear you. Want to explore what this brings up for you?\",\n",
    "        \"That sounds meaningful. How does it feel for you internally?\",\n",
    "        \"Thanks for telling me that. What’s the emotion behind it?\",\n",
    "        \"I’m listening—how is this affecting you today?\",\n",
    "        \"That seems important. What part stands out emotionally?\",\n",
    "        \"Thanks for opening up. What’s moving inside you as you say that?\",\n",
    "        \"I hear what you’re saying. What feeling comes up with it?\"\n",
    "    ],\n",
    "\n",
    "    \"default\": [\n",
    "        \"Thank you for sharing that. How are you feeling about it?\",\n",
    "        \"I’m listening. Want to tell me more about what’s going on?\",\n",
    "        \"That sounds meaningful—what does it bring up for you?\",\n",
    "        \"Thanks for telling me. What emotion is underneath that?\",\n",
    "        \"I hear you. What’s happening inside as you think about this?\",\n",
    "        \"That’s important. How did it make you feel?\",\n",
    "        \"I’m here with you. What’s coming up emotionally?\",\n",
    "        \"Tell me more—what part of this matters most to you?\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "# Map label names in GoEmotions to the canonical keys above (adjust as needed)\n",
    "GOEMO_TO_CANON = {\n",
    "    \"admiration\":\"neutral\",\"amusement\":\"joy\",\"anger\":\"anger\",\"annoyance\":\"anger\",\n",
    "    \"approval\":\"neutral\",\"caring\":\"love\",\"confusion\":\"neutral\",\"curiosity\":\"neutral\",\n",
    "    \"desire\":\"neutral\",\"disappointment\":\"sadness\",\"disapproval\":\"neutral\",\"disgust\":\"disgust\" if \"disgust\" in TEMPLATES else \"default\",\n",
    "    \"embarrassment\":\"neutral\",\"excitement\":\"joy\",\"fear\":\"fear\",\"gratitude\":\"neutral\",\n",
    "    \"grief\":\"sadness\",\"joy\":\"joy\",\"love\":\"love\",\"nervousness\":\"anxiety\",\n",
    "    \"optimism\":\"joy\",\"pride\":\"joy\",\"realization\":\"neutral\",\"relief\":\"joy\",\n",
    "    \"remorse\":\"sadness\",\"sadness\":\"sadness\",\"surprise\":\"neutral\",\"neutral\":\"neutral\"\n",
    "}\n",
    "# If TEMPLATES lacks a key, GOEMO_TO_CANON will fallback later\n",
    "\n",
    "# ========== Helper functions ==========\n",
    "def load_any_csv_or_jsonl(path: str) -> pd.DataFrame:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "    if p.suffix.lower() in [\".csv\", \".tsv\"]:\n",
    "        sep = \"\\t\" if p.suffix.lower()==\".tsv\" else \",\"\n",
    "        df = pd.read_csv(path, sep=sep, dtype=str, keep_default_na=False)\n",
    "        return df\n",
    "    elif p.suffix.lower() in [\".jsonl\", \".ndjson\", \".json\"]:\n",
    "        # try json lines\n",
    "        try:\n",
    "            df = pd.read_json(path, lines=True)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            # try loading as plain json\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                j = json.load(f)\n",
    "            # If it's a dict with 'data' key, try flattening\n",
    "            if isinstance(j, dict) and \"data\" in j:\n",
    "                df = pd.json_normalize(j[\"data\"])\n",
    "                return df\n",
    "            # fallback: normalize the object list\n",
    "            df = pd.json_normalize(j)\n",
    "            return df\n",
    "    else:\n",
    "        # try CSV by default\n",
    "        df = pd.read_csv(path, dtype=str, keep_default_na=False)\n",
    "        return df\n",
    "\n",
    "def pretty_head(df: pd.DataFrame, n=10):\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(\"Columns:\", list(df.columns))\n",
    "    display(df.head(n))\n",
    "\n",
    "def safe_get_cols(df, candidates):\n",
    "    \"\"\"Return first matching column name from candidates\"\"\"\n",
    "    cols = [c.lower() for c in df.columns]\n",
    "    for cand in candidates:\n",
    "        if cand.lower() in cols:\n",
    "            return df.columns[cols.index(cand.lower())]\n",
    "    return None\n",
    "\n",
    "def split_sentences(text: str) -> List[str]:\n",
    "    if text is None: return []\n",
    "    s = str(text).strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    # naive split by punctuation and newlines\n",
    "    parts = re.split(r'(?<=[.!?])\\s+|\\n+', s)\n",
    "    clean = [p.strip() for p in parts if len(p.strip())>2]\n",
    "    return clean\n",
    "\n",
    "def choose_template_for_emotions(emotions: List[str]) -> str:\n",
    "    # emotions: list of raw labels like [\"sadness\",\"anxiety\"]\n",
    "    for pref in [\"sadness\",\"anxiety\",\"fear\",\"anger\",\"joy\",\"love\",\"neutral\"]:\n",
    "        if pref in emotions and pref in TEMPLATES:\n",
    "            return random.choice(TEMPLATES[pref])\n",
    "    # try mapping via GOEMO_TO_CANON if raw labels are different\n",
    "    for e in emotions:\n",
    "        canon = GOEMO_TO_CANON.get(e, None)\n",
    "        if canon and canon in TEMPLATES:\n",
    "            return random.choice(TEMPLATES[canon])\n",
    "    # fallback\n",
    "    return random.choice(TEMPLATES.get(\"default\", list(TEMPLATES.values())[0]))\n",
    "\n",
    "# ========== Load & inspect datasets ==========\n",
    "all_samples = []  # will hold tuples (user_text, compatika_reply, source)\n",
    "\n",
    "# ---- EmpatheticDialogues ----\n",
    "if os.path.exists(empathetic_path):\n",
    "    edf = load_any_csv_or_jsonl(empathetic_path)\n",
    "    print(\"EmpatheticDialogues loaded:\")\n",
    "    pretty_head(edf, n=3)\n",
    "    # try to find columns: context/emotion, prompt, utterance, speaker\n",
    "    # common col names: 'context','utterance','emotion','speaker_idx','conv_id','prompt'\n",
    "    user_col = safe_get_cols(edf, [\"context\",\"context_text\",\"user\",\"prompt\"])\n",
    "    utt_col = safe_get_cols(edf, [\"utterance\",\"response\",\"text\",\"reply\"])\n",
    "    emotion_col = safe_get_cols(edf, [\"emotion\",\"label\",\"emotions\"])\n",
    "    # If this dataset is multi-turn with conv_id and utterance_idx, we want user->assistant pairs.\n",
    "    # Heuristic: if 'speaker' or 'speaker_idx' exists, use it.\n",
    "    speaker_col = safe_get_cols(edf, [\"speaker\",\"speaker_idx\",\"role\"])\n",
    "    if 'conv_id' in edf.columns and 'utterance_idx' in edf.columns and speaker_col:\n",
    "        # group by conv and pair user -> assistant replies (speaker idx convention varies; we will assume 0=person,1=assistant)\n",
    "        for conv_id, group in edf.groupby(\"conv_id\"):\n",
    "            grp = group.sort_values(by=\"utterance_idx\")\n",
    "            # iterate; whenever we find a user turn followed by assistant turn, pair them\n",
    "            prev = None\n",
    "            for _, row in grp.iterrows():\n",
    "                role = str(row.get(speaker_col, \"\")).strip()\n",
    "                text = str(row.get(utt_col, row.get(user_col, \"\"))).strip()\n",
    "                if not text:\n",
    "                    continue\n",
    "                if prev and prev['role'].lower() != role.lower():\n",
    "                    # prev and current are different roles -> make pair prev.text -> current.text\n",
    "                    all_samples.append((prev['text'], text, \"empathetic\"))\n",
    "                prev = {\"role\": role, \"text\": text}\n",
    "    else:\n",
    "        # fallback: if we have context + utterance columns where context is user and utterance is reply\n",
    "        if user_col and utt_col:\n",
    "            for _, row in edf.iterrows():\n",
    "                u = str(row.get(user_col,\"\")).strip()\n",
    "                r = str(row.get(utt_col,\"\")).strip()\n",
    "                if u and r:\n",
    "                    all_samples.append((u, r, \"empathetic\"))\n",
    "        else:\n",
    "            # as last resort, try to use any 'text' and 'response' like columns\n",
    "            for col in edf.columns:\n",
    "                if \"utter\" in col.lower() or \"resp\" in col.lower():\n",
    "                    utt_col = col\n",
    "                    break\n",
    "            # skip if still nothing\n",
    "    print(f\"Collected {len([s for s in all_samples if s[2]=='empathetic'])} empathetic pairs so far.\")\n",
    "else:\n",
    "    print(\"EmpatheticDialogues path not found, skipping.\")\n",
    "\n",
    "# ---- GoEmotions ----\n",
    "if os.path.exists(goemotions_path):\n",
    "    gdf = load_any_csv_or_jsonl(goemotions_path)\n",
    "    print(\"\\nGoEmotions loaded:\")\n",
    "    pretty_head(gdf, n=3)\n",
    "    # Common formats: columns 'text', 'labels' (comma separated), or many one-hot columns per emotion\n",
    "    if \"text\" in gdf.columns and \"labels\" in gdf.columns:\n",
    "        for _, row in gdf.iterrows():\n",
    "            text = str(row[\"text\"]).strip()\n",
    "            labels_raw = str(row[\"labels\"]).strip()\n",
    "            if not text:\n",
    "                continue\n",
    "            labels = [l.strip() for l in labels_raw.split(\",\") if l.strip()]\n",
    "            # choose template based on labels\n",
    "            reply = choose_template_for_emotions(labels)\n",
    "            all_samples.append((text, reply, \"goemotions\"))\n",
    "    else:\n",
    "        # check for one-hot emotion columns\n",
    "        emotion_cols = [c for c in gdf.columns if c.lower() in GOEMO_TO_CANON.keys()]\n",
    "        if emotion_cols:\n",
    "            for _, row in gdf.iterrows():\n",
    "                text = str(row.get(\"text\",\"\")).strip()\n",
    "                if not text:\n",
    "                    continue\n",
    "                labels = [c for c in emotion_cols if str(row.get(c,\"\")) not in [\"0\",\"False\",\"\",\"0.0\"]]\n",
    "                labels = [c for c in labels if c]\n",
    "                reply = choose_template_for_emotions(labels if labels else [\"neutral\"])\n",
    "                all_samples.append((text, reply, \"goemotions\"))\n",
    "        else:\n",
    "            # fallback: if single 'label' column exists\n",
    "            label_col = safe_get_cols(gdf, [\"label\",\"emotion\",\"labels\"])\n",
    "            if label_col and \"text\" in gdf.columns:\n",
    "                for _, row in gdf.iterrows():\n",
    "                    text = str(row[\"text\"]).strip()\n",
    "                    labels = [l.strip() for l in str(row.get(label_col,\"\")).split(\",\") if l.strip()]\n",
    "                    reply = choose_template_for_emotions(labels)\n",
    "                    all_samples.append((text, reply, \"goemotions\"))\n",
    "    print(f\"Collected {len([s for s in all_samples if s[2]=='goemotions'])} goemotions pairs so far.\")\n",
    "else:\n",
    "    print(\"GoEmotions path not found, skipping.\")\n",
    "\n",
    "# ---- PersonaChat (convert to empathetic probes) ----\n",
    "if os.path.exists(persona_path):\n",
    "    pdf = load_any_csv_or_jsonl(persona_path)\n",
    "    print(\"\\nPersona dataset loaded:\")\n",
    "    pretty_head(pdf, n=3)\n",
    "    text_col = safe_get_cols(pdf, [\"chat\",\"utterance\",\"text\",\"message\",\"persona_dialog\",\"dialog\"])\n",
    "    if text_col is None:\n",
    "        # fallback to longest string column\n",
    "        object_cols = [c for c in pdf.columns if pdf[c].dtype == object]\n",
    "        if object_cols:\n",
    "            lengths = {c: pdf[c].astype(str).map(len).mean() for c in object_cols}\n",
    "            text_col = max(lengths, key=lengths.get)\n",
    "    print(\"Using persona text column:\", text_col)\n",
    "    # split each cell into sentences and convert to probes/reflections\n",
    "    for _, row in pdf.iterrows():\n",
    "        cell = str(row.get(text_col,\"\")).strip()\n",
    "        if not cell:\n",
    "            continue\n",
    "        sents = split_sentences(cell)\n",
    "        for s in sents:\n",
    "            # optionally ignore pure persona facts (short facts), but we include them and probe feelings\n",
    "            reply = random.choice(TEMPLATES.get(\"neutral\", TEMPLATES.get(\"default\")))\n",
    "            # pick better mapping: if sentence contains emotion keywords, pick support\n",
    "            # simple check:\n",
    "            lower = s.lower()\n",
    "            if any(k in lower for k in [\"sad\",\"lonely\",\"depress\",\"hurt\",\"angry\",\"scared\",\"nervous\",\"anxious\"]):\n",
    "                # pick sadness/anxiety support\n",
    "                reply = choose_template_for_emotions([\"sadness\"])\n",
    "            all_samples.append((s, reply, \"persona\"))\n",
    "    print(f\"Collected {len([s for s in all_samples if s[2]=='persona'])} persona-derived pairs so far.\")\n",
    "else:\n",
    "    print(\"Persona path not found, skipping.\")\n",
    "\n",
    "# ========== Merge, dedupe, shuffle ==========\n",
    "print(\"\\nTotal raw samples collected:\", len(all_samples))\n",
    "# Normalize whitespace and simple cleaning\n",
    "def normalize_text(t: str) -> str:\n",
    "    t = re.sub(r'\\s+', ' ', t).strip()\n",
    "    return t\n",
    "\n",
    "norm_pairs = []\n",
    "seen = set()\n",
    "for u, r, src in all_samples:\n",
    "    u2 = normalize_text(u)\n",
    "    r2 = normalize_text(r)\n",
    "    key = (u2.lower(), r2.lower())\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    norm_pairs.append((u2, r2, src))\n",
    "\n",
    "print(\"After dedupe:\", len(norm_pairs))\n",
    "\n",
    "random.shuffle(norm_pairs)\n",
    "\n",
    "# Optionally expand until target size (MB) by repeating with small paraphrase variations\n",
    "if TARGET_SIZE_MB is not None:\n",
    "    target_bytes = int(TARGET_SIZE_MB * 1024 * 1024)\n",
    "    est = 0\n",
    "    out_lines = []\n",
    "    idx = 0\n",
    "    # small paraphrase function: randomly swap templates for same source\n",
    "    def paraphrase_reply(reply):\n",
    "        # naive: just return reply (you can add simple synonyms or template variations here)\n",
    "        return reply\n",
    "    while est < target_bytes:\n",
    "        u, r, s = norm_pairs[idx % len(norm_pairs)]\n",
    "        r2 = paraphrase_reply(r)\n",
    "        sample = f\"USER: {u}\\nCOMPATIKA: {r2}\\n\\n\"\n",
    "        out_lines.append(sample)\n",
    "        est += len(sample.encode(\"utf-8\"))\n",
    "        idx += 1\n",
    "    print(f\"Expanded to {len(out_lines)} lines to reach ~{TARGET_SIZE_MB} MB\")\n",
    "    Path(output_txt).write_text(\"\".join(out_lines), encoding=\"utf-8\")\n",
    "else:\n",
    "    # write all normalized pairs to TXT\n",
    "    with open(output_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        for u, r, s in norm_pairs:\n",
    "            f.write(f\"USER: {u}\\nCOMPATIKA: {r}\\n\\n\")\n",
    "    print(f\"Wrote {len(norm_pairs)} samples to {output_txt} (size: {os.path.getsize(output_txt)/(1024*1024):.2f} MB)\")\n",
    "\n",
    "# ========== Done ==========\n",
    "print(\"Done. Sample output preview:\")\n",
    "with open(output_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    preview = \"\".join([next(f) for _ in range(20)]) if os.path.getsize(output_txt)>0 else \"\"\n",
    "print(preview)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327e3869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
