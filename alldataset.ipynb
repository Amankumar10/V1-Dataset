{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb35db06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmpatheticDialogues loaded:\n",
      "Shape: (76673, 8)\n",
      "Columns: ['conv_id', 'utterance_idx', 'context', 'prompt', 'speaker_idx', 'utterance', 'selfeval', 'tags']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>utterance</th>\n",
       "      <th>selfeval</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>1</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>1</td>\n",
       "      <td>I remember going to see the fireworks with my ...</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>2</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>0</td>\n",
       "      <td>Was this a friend you were in love with_comma_...</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>3</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>1</td>\n",
       "      <td>This was a best friend. I miss her.</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        conv_id utterance_idx      context  \\\n",
       "0  hit:0_conv:1             1  sentimental   \n",
       "1  hit:0_conv:1             2  sentimental   \n",
       "2  hit:0_conv:1             3  sentimental   \n",
       "\n",
       "                                              prompt speaker_idx  \\\n",
       "0  I remember going to the fireworks with my best...           1   \n",
       "1  I remember going to the fireworks with my best...           0   \n",
       "2  I remember going to the fireworks with my best...           1   \n",
       "\n",
       "                                           utterance     selfeval tags  \n",
       "0  I remember going to see the fireworks with my ...  5|5|5_2|2|5       \n",
       "1  Was this a friend you were in love with_comma_...  5|5|5_2|2|5       \n",
       "2                This was a best friend. I miss her.  5|5|5_2|2|5       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 58829 empathetic pairs so far.\n",
      "\n",
      "GoEmotions loaded:\n",
      "Shape: (211225, 38)\n",
      "Columns: ['text', 'id', 'author', 'subreddit', 'link_id', 'parent_id', 'created_utc', 'rater_id', 'example_very_unclear', 'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral', 'clean_text']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>example_very_unclear</th>\n",
       "      <th>admiration</th>\n",
       "      <th>...</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>eew5j0j</td>\n",
       "      <td>Brdd9</td>\n",
       "      <td>nrl</td>\n",
       "      <td>t3_ajis4z</td>\n",
       "      <td>t1_eew18eq</td>\n",
       "      <td>1548381039.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>that game hurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;sexuality shouldn’t be a grouping category I...</td>\n",
       "      <td>eemcysk</td>\n",
       "      <td>TheGreen888</td>\n",
       "      <td>unpopularopinion</td>\n",
       "      <td>t3_ai4q37</td>\n",
       "      <td>t3_ai4q37</td>\n",
       "      <td>1548084169.0</td>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sexuality shouldn t be a grouping category it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>ed2mah1</td>\n",
       "      <td>Labalool</td>\n",
       "      <td>confessions</td>\n",
       "      <td>t3_abru74</td>\n",
       "      <td>t1_ed2m7g7</td>\n",
       "      <td>1546427744.0</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>you do right if you don t care then fuck em</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       id       author  \\\n",
       "0                                    That game hurt.  eew5j0j        Brdd9   \n",
       "1   >sexuality shouldn’t be a grouping category I...  eemcysk  TheGreen888   \n",
       "2     You do right, if you don't care then fuck 'em!  ed2mah1     Labalool   \n",
       "\n",
       "          subreddit    link_id   parent_id   created_utc rater_id  \\\n",
       "0               nrl  t3_ajis4z  t1_eew18eq  1548381039.0        1   \n",
       "1  unpopularopinion  t3_ai4q37   t3_ai4q37  1548084169.0       37   \n",
       "2       confessions  t3_abru74  t1_ed2m7g7  1546427744.0       37   \n",
       "\n",
       "  example_very_unclear admiration  ... nervousness optimism pride realization  \\\n",
       "0                False          0  ...           0        0     0           0   \n",
       "1                 True          0  ...           0        0     0           0   \n",
       "2                False          0  ...           0        0     0           0   \n",
       "\n",
       "  relief remorse sadness surprise neutral  \\\n",
       "0      0       0       1        0       0   \n",
       "1      0       0       0        0       0   \n",
       "2      0       0       0        0       1   \n",
       "\n",
       "                                          clean_text  \n",
       "0                                     that game hurt  \n",
       "1  sexuality shouldn t be a grouping category it ...  \n",
       "2        you do right if you don t care then fuck em  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 211225 goemotions pairs so far.\n",
      "\n",
      "Persona dataset loaded:\n",
      "Shape: (8939, 3)\n",
      "Columns: ['Unnamed: 0', 'Persona', 'chat']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Persona</th>\n",
       "      <th>chat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>i like to remodel homes. i like to go hunting...</td>\n",
       "      <td>hi , how are you doing ? i am getting ready to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>my mom is my best friend. i have four sisters...</td>\n",
       "      <td>hi , how are you doing today ?\\ni am spending ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>i had a gig at local theater last night. i wo...</td>\n",
       "      <td>we all live in a yellow submarine , a yellow s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                            Persona  \\\n",
       "0          0   i like to remodel homes. i like to go hunting...   \n",
       "1          1   my mom is my best friend. i have four sisters...   \n",
       "2          2   i had a gig at local theater last night. i wo...   \n",
       "\n",
       "                                                chat  \n",
       "0  hi , how are you doing ? i am getting ready to...  \n",
       "1  hi , how are you doing today ?\\ni am spending ...  \n",
       "2  we all live in a yellow submarine , a yellow s...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using persona text column: chat\n",
      "Collected 210777 persona-derived pairs so far.\n",
      "\n",
      "Total raw samples collected: 480831\n",
      "After dedupe: 422648\n",
      "Wrote 422648 samples to compatika_combined.txt (size: 43.74 MB)\n",
      "Done. Sample output preview:\n",
      "USER: Just give me 20 million dollars and let me retire early. gg wp life\n",
      "COMPATIKA: Thanks for opening up.\n",
      "\n",
      "USER: i stay home with the kids , my wife is a baker .\n",
      "COMPATIKA: I’m listening.\n",
      "\n",
      "USER: that is cool what is your favorite band ?\n",
      "COMPATIKA: I’m listening.\n",
      "\n",
      "USER: do you like hiking\n",
      "COMPATIKA: Thanks for telling me that.\n",
      "\n",
      "USER: That's the funniest mental image I've had in a very long time!\n",
      "COMPATIKA: It sounds like something truly uplifting happened.\n",
      "\n",
      "USER: Don't you even dare try to put any blame on [NAME]\n",
      "COMPATIKA: I hear your frustration.\n",
      "\n",
      "USER: [NAME] has no touch..That is why [NAME] kept dropping the ball..\n",
      "COMPATIKA: Thanks for telling me that.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combined dataset builder for Compatika V1\n",
    "# Supports: EmpatheticDialogues, GoEmotions, PersonaChat (CSV or JSONL)\n",
    "# Output: compatika_combined.txt (USER / COMPATIKA pairs)\n",
    "# Run in Jupyter. Edit dataset path variables below.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "# ========== CONFIG - set these paths ==========\n",
    "empathetic_path = r\"C:\\Users\\aman\\Desktop\\v1 dataset\\rawdata\\empathetic_dialogues\\train.csv\"   # or .jsonl\n",
    "goemotions_path = r\"C:\\Users\\aman\\Desktop\\v1 dataset\\rawdata\\goemotions_1\\goemotions_merged_clean.csv\"            # or .jsonl\n",
    "persona_path = r\"C:\\Users\\aman\\Desktop\\v1 dataset\\rawdata\\PersonaChat\\personality.csv\"                  # or .jsonl\n",
    "\n",
    "output_txt = \"compatika_combined.txt\"\n",
    "TARGET_SIZE_MB = None  # set to e.g. 40 to attempt ~40MB output, or None to just write all samples\n",
    "\n",
    "# ========== Templates / mappings ==========\n",
    "# Emotion -> templates (extend these lists to increase variety)\n",
    "TEMPLATES = {\n",
    "    \"sadness\": [\n",
    "        \"That sounds really painful, and it’s okay to feel this way.\",\n",
    "        \"I’m sorry you’re feeling this. I’m here with you.\",\n",
    "        \"It makes sense that this feels heavy.\",\n",
    "        \"That sadness sounds real, and you deserve space to feel it.\",\n",
    "        \"It sounds like your heart is carrying a lot right now.\",\n",
    "        \"I hear how much this affected you.\",\n",
    "        \"It’s understandable you’d feel sad about that.\",\n",
    "        \"I’m here with you as these emotions come up.\"\n",
    "    ],\n",
    "\n",
    "    \"anger\": [\n",
    "        \"It makes sense to feel angry about that.\",\n",
    "        \"I hear your frustration.\",\n",
    "        \"Your anger is valid.\",\n",
    "        \"It sounds like something really bothered you.\",\n",
    "        \"That reaction shows how much this mattered to you.\",\n",
    "        \"I can feel the intensity in what you shared.\",\n",
    "        \"It’s okay to feel upset.\",\n",
    "        \"That frustration you’re feeling is real.\"\n",
    "    ],\n",
    "\n",
    "    \"anxiety\": [\n",
    "        \"Feeling anxious can be exhausting.\",\n",
    "        \"It’s okay to feel nervous.\",\n",
    "        \"That tension sounds heavy.\",\n",
    "        \"You’re not alone—anxiety can feel overwhelming.\",\n",
    "        \"It makes sense your body reacted that way.\",\n",
    "        \"That sounds stressful.\",\n",
    "        \"I hear your worry.\",\n",
    "        \"You’re carrying a lot of tension.\"\n",
    "    ],\n",
    "\n",
    "    \"fear\": [\n",
    "        \"That sounds scary, and I’m here with you.\",\n",
    "        \"It’s understandable to feel afraid.\",\n",
    "        \"That fear sounds real.\",\n",
    "        \"You’re safe here.\",\n",
    "        \"It makes sense that you’re scared.\",\n",
    "        \"That moment sounded really frightening.\",\n",
    "        \"Fear can be overwhelming.\",\n",
    "        \"You’re not alone in that feeling.\"\n",
    "    ],\n",
    "\n",
    "    \"joy\": [\n",
    "        \"That’s wonderful to hear.\",\n",
    "        \"I’m glad you’re feeling joyful.\",\n",
    "        \"That’s such a warm moment.\",\n",
    "        \"It sounds like something truly uplifting happened.\",\n",
    "        \"I can hear the happiness in your words.\",\n",
    "        \"That joy sounds genuine.\",\n",
    "        \"That feels like a bright spot.\",\n",
    "        \"It’s lovely to hear something positive.\"\n",
    "    ],\n",
    "\n",
    "    \"love\": [\n",
    "        \"That’s a warm and meaningful feeling.\",\n",
    "        \"It sounds meaningful to feel that way.\",\n",
    "        \"That affection seems deep.\",\n",
    "        \"That sounds like a heartfelt connection.\",\n",
    "        \"It’s a beautiful emotion.\",\n",
    "        \"I can feel the warmth in that.\",\n",
    "        \"Love can carry many layers.\",\n",
    "        \"It sounds like something very important to you.\"\n",
    "    ],\n",
    "\n",
    "    \"neutral\": [\n",
    "        \"Thanks for sharing that.\",\n",
    "        \"I hear you.\",\n",
    "        \"That sounds meaningful.\",\n",
    "        \"Thanks for telling me that.\",\n",
    "        \"I’m listening.\",\n",
    "        \"That seems important.\",\n",
    "        \"Thanks for opening up.\",\n",
    "        \"I hear what you’re saying.\"\n",
    "    ],\n",
    "\n",
    "    \"default\": [\n",
    "        \"Thank you for sharing that.\",\n",
    "        \"I’m listening.\",\n",
    "        \"That sounds meaningful.\",\n",
    "        \"Thanks for telling me.\",\n",
    "        \"I hear you.\",\n",
    "        \"That’s important.\",\n",
    "        \"I’m here with you.\",\n",
    "        \"I’m here with whatever you’re feeling.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Map label names in GoEmotions to the canonical keys above (adjust as needed)\n",
    "GOEMO_TO_CANON = {\n",
    "    \"admiration\":\"neutral\",\"amusement\":\"joy\",\"anger\":\"anger\",\"annoyance\":\"anger\",\n",
    "    \"approval\":\"neutral\",\"caring\":\"love\",\"confusion\":\"neutral\",\"curiosity\":\"neutral\",\n",
    "    \"desire\":\"neutral\",\"disappointment\":\"sadness\",\"disapproval\":\"neutral\",\"disgust\":\"disgust\" if \"disgust\" in TEMPLATES else \"default\",\n",
    "    \"embarrassment\":\"neutral\",\"excitement\":\"joy\",\"fear\":\"fear\",\"gratitude\":\"neutral\",\n",
    "    \"grief\":\"sadness\",\"joy\":\"joy\",\"love\":\"love\",\"nervousness\":\"anxiety\",\n",
    "    \"optimism\":\"joy\",\"pride\":\"joy\",\"realization\":\"neutral\",\"relief\":\"joy\",\n",
    "    \"remorse\":\"sadness\",\"sadness\":\"sadness\",\"surprise\":\"neutral\",\"neutral\":\"neutral\"\n",
    "}\n",
    "# If TEMPLATES lacks a key, GOEMO_TO_CANON will fallback later\n",
    "\n",
    "# ========== Helper functions ==========\n",
    "def load_any_csv_or_jsonl(path: str) -> pd.DataFrame:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "    if p.suffix.lower() in [\".csv\", \".tsv\"]:\n",
    "        sep = \"\\t\" if p.suffix.lower()==\".tsv\" else \",\"\n",
    "        df = pd.read_csv(path, sep=sep, dtype=str, keep_default_na=False)\n",
    "        return df\n",
    "    elif p.suffix.lower() in [\".jsonl\", \".ndjson\", \".json\"]:\n",
    "        # try json lines\n",
    "        try:\n",
    "            df = pd.read_json(path, lines=True)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            # try loading as plain json\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                j = json.load(f)\n",
    "            # If it's a dict with 'data' key, try flattening\n",
    "            if isinstance(j, dict) and \"data\" in j:\n",
    "                df = pd.json_normalize(j[\"data\"])\n",
    "                return df\n",
    "            # fallback: normalize the object list\n",
    "            df = pd.json_normalize(j)\n",
    "            return df\n",
    "    else:\n",
    "        # try CSV by default\n",
    "        df = pd.read_csv(path, dtype=str, keep_default_na=False)\n",
    "        return df\n",
    "\n",
    "def pretty_head(df: pd.DataFrame, n=10):\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(\"Columns:\", list(df.columns))\n",
    "    display(df.head(n))\n",
    "\n",
    "def safe_get_cols(df, candidates):\n",
    "    \"\"\"Return first matching column name from candidates\"\"\"\n",
    "    cols = [c.lower() for c in df.columns]\n",
    "    for cand in candidates:\n",
    "        if cand.lower() in cols:\n",
    "            return df.columns[cols.index(cand.lower())]\n",
    "    return None\n",
    "\n",
    "def split_sentences(text: str) -> List[str]:\n",
    "    if text is None: return []\n",
    "    s = str(text).strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    # naive split by punctuation and newlines\n",
    "    parts = re.split(r'(?<=[.!?])\\s+|\\n+', s)\n",
    "    clean = [p.strip() for p in parts if len(p.strip())>2]\n",
    "    return clean\n",
    "\n",
    "def choose_template_for_emotions(emotions: List[str]) -> str:\n",
    "    # emotions: list of raw labels like [\"sadness\",\"anxiety\"]\n",
    "    for pref in [\"sadness\",\"anxiety\",\"fear\",\"anger\",\"joy\",\"love\",\"neutral\"]:\n",
    "        if pref in emotions and pref in TEMPLATES:\n",
    "            return random.choice(TEMPLATES[pref])\n",
    "    # try mapping via GOEMO_TO_CANON if raw labels are different\n",
    "    for e in emotions:\n",
    "        canon = GOEMO_TO_CANON.get(e, None)\n",
    "        if canon and canon in TEMPLATES:\n",
    "            return random.choice(TEMPLATES[canon])\n",
    "    # fallback\n",
    "    return random.choice(TEMPLATES.get(\"default\", list(TEMPLATES.values())[0]))\n",
    "\n",
    "# ========== Load & inspect datasets ==========\n",
    "all_samples = []  # will hold tuples (user_text, compatika_reply, source)\n",
    "\n",
    "# ---- EmpatheticDialogues ----\n",
    "if os.path.exists(empathetic_path):\n",
    "    edf = load_any_csv_or_jsonl(empathetic_path)\n",
    "    print(\"EmpatheticDialogues loaded:\")\n",
    "    pretty_head(edf, n=3)\n",
    "    # try to find columns: context/emotion, prompt, utterance, speaker\n",
    "    # common col names: 'context','utterance','emotion','speaker_idx','conv_id','prompt'\n",
    "    user_col = safe_get_cols(edf, [\"context\",\"context_text\",\"user\",\"prompt\"])\n",
    "    utt_col = safe_get_cols(edf, [\"utterance\",\"response\",\"text\",\"reply\"])\n",
    "    emotion_col = safe_get_cols(edf, [\"emotion\",\"label\",\"emotions\"])\n",
    "    # If this dataset is multi-turn with conv_id and utterance_idx, we want user->assistant pairs.\n",
    "    # Heuristic: if 'speaker' or 'speaker_idx' exists, use it.\n",
    "    speaker_col = safe_get_cols(edf, [\"speaker\",\"speaker_idx\",\"role\"])\n",
    "    if 'conv_id' in edf.columns and 'utterance_idx' in edf.columns and speaker_col:\n",
    "        # group by conv and pair user -> assistant replies (speaker idx convention varies; we will assume 0=person,1=assistant)\n",
    "        for conv_id, group in edf.groupby(\"conv_id\"):\n",
    "            grp = group.sort_values(by=\"utterance_idx\")\n",
    "            # iterate; whenever we find a user turn followed by assistant turn, pair them\n",
    "            prev = None\n",
    "            for _, row in grp.iterrows():\n",
    "                role = str(row.get(speaker_col, \"\")).strip()\n",
    "                text = str(row.get(utt_col, row.get(user_col, \"\"))).strip()\n",
    "                if not text:\n",
    "                    continue\n",
    "                if prev and prev['role'].lower() != role.lower():\n",
    "                    # prev and current are different roles -> make pair prev.text -> current.text\n",
    "                    all_samples.append((prev['text'], text, \"empathetic\"))\n",
    "                prev = {\"role\": role, \"text\": text}\n",
    "    else:\n",
    "        # fallback: if we have context + utterance columns where context is user and utterance is reply\n",
    "        if user_col and utt_col:\n",
    "            for _, row in edf.iterrows():\n",
    "                u = str(row.get(user_col,\"\")).strip()\n",
    "                r = str(row.get(utt_col,\"\")).strip()\n",
    "                if u and r:\n",
    "                    all_samples.append((u, r, \"empathetic\"))\n",
    "        else:\n",
    "            # as last resort, try to use any 'text' and 'response' like columns\n",
    "            for col in edf.columns:\n",
    "                if \"utter\" in col.lower() or \"resp\" in col.lower():\n",
    "                    utt_col = col\n",
    "                    break\n",
    "            # skip if still nothing\n",
    "    print(f\"Collected {len([s for s in all_samples if s[2]=='empathetic'])} empathetic pairs so far.\")\n",
    "else:\n",
    "    print(\"EmpatheticDialogues path not found, skipping.\")\n",
    "\n",
    "# ---- GoEmotions ----\n",
    "if os.path.exists(goemotions_path):\n",
    "    gdf = load_any_csv_or_jsonl(goemotions_path)\n",
    "    print(\"\\nGoEmotions loaded:\")\n",
    "    pretty_head(gdf, n=3)\n",
    "    # Common formats: columns 'text', 'labels' (comma separated), or many one-hot columns per emotion\n",
    "    if \"text\" in gdf.columns and \"labels\" in gdf.columns:\n",
    "        for _, row in gdf.iterrows():\n",
    "            text = str(row[\"text\"]).strip()\n",
    "            labels_raw = str(row[\"labels\"]).strip()\n",
    "            if not text:\n",
    "                continue\n",
    "            labels = [l.strip() for l in labels_raw.split(\",\") if l.strip()]\n",
    "            # choose template based on labels\n",
    "            reply = choose_template_for_emotions(labels)\n",
    "            all_samples.append((text, reply, \"goemotions\"))\n",
    "    else:\n",
    "        # check for one-hot emotion columns\n",
    "        emotion_cols = [c for c in gdf.columns if c.lower() in GOEMO_TO_CANON.keys()]\n",
    "        if emotion_cols:\n",
    "            for _, row in gdf.iterrows():\n",
    "                text = str(row.get(\"text\",\"\")).strip()\n",
    "                if not text:\n",
    "                    continue\n",
    "                labels = [c for c in emotion_cols if str(row.get(c,\"\")) not in [\"0\",\"False\",\"\",\"0.0\"]]\n",
    "                labels = [c for c in labels if c]\n",
    "                reply = choose_template_for_emotions(labels if labels else [\"neutral\"])\n",
    "                all_samples.append((text, reply, \"goemotions\"))\n",
    "        else:\n",
    "            # fallback: if single 'label' column exists\n",
    "            label_col = safe_get_cols(gdf, [\"label\",\"emotion\",\"labels\"])\n",
    "            if label_col and \"text\" in gdf.columns:\n",
    "                for _, row in gdf.iterrows():\n",
    "                    text = str(row[\"text\"]).strip()\n",
    "                    labels = [l.strip() for l in str(row.get(label_col,\"\")).split(\",\") if l.strip()]\n",
    "                    reply = choose_template_for_emotions(labels)\n",
    "                    all_samples.append((text, reply, \"goemotions\"))\n",
    "    print(f\"Collected {len([s for s in all_samples if s[2]=='goemotions'])} goemotions pairs so far.\")\n",
    "else:\n",
    "    print(\"GoEmotions path not found, skipping.\")\n",
    "\n",
    "# ---- PersonaChat (convert to empathetic probes) ----\n",
    "if os.path.exists(persona_path):\n",
    "    pdf = load_any_csv_or_jsonl(persona_path)\n",
    "    print(\"\\nPersona dataset loaded:\")\n",
    "    pretty_head(pdf, n=3)\n",
    "    text_col = safe_get_cols(pdf, [\"chat\",\"utterance\",\"text\",\"message\",\"persona_dialog\",\"dialog\"])\n",
    "    if text_col is None:\n",
    "        # fallback to longest string column\n",
    "        object_cols = [c for c in pdf.columns if pdf[c].dtype == object]\n",
    "        if object_cols:\n",
    "            lengths = {c: pdf[c].astype(str).map(len).mean() for c in object_cols}\n",
    "            text_col = max(lengths, key=lengths.get)\n",
    "    print(\"Using persona text column:\", text_col)\n",
    "    # split each cell into sentences and convert to probes/reflections\n",
    "    for _, row in pdf.iterrows():\n",
    "        cell = str(row.get(text_col,\"\")).strip()\n",
    "        if not cell:\n",
    "            continue\n",
    "        sents = split_sentences(cell)\n",
    "        for s in sents:\n",
    "            # optionally ignore pure persona facts (short facts), but we include them and probe feelings\n",
    "            reply = random.choice(TEMPLATES.get(\"neutral\", TEMPLATES.get(\"default\")))\n",
    "            # pick better mapping: if sentence contains emotion keywords, pick support\n",
    "            # simple check:\n",
    "            lower = s.lower()\n",
    "            if any(k in lower for k in [\"sad\",\"lonely\",\"depress\",\"hurt\",\"angry\",\"scared\",\"nervous\",\"anxious\"]):\n",
    "                # pick sadness/anxiety support\n",
    "                reply = choose_template_for_emotions([\"sadness\"])\n",
    "            all_samples.append((s, reply, \"persona\"))\n",
    "    print(f\"Collected {len([s for s in all_samples if s[2]=='persona'])} persona-derived pairs so far.\")\n",
    "else:\n",
    "    print(\"Persona path not found, skipping.\")\n",
    "\n",
    "# ========== Merge, dedupe, shuffle ==========\n",
    "print(\"\\nTotal raw samples collected:\", len(all_samples))\n",
    "# Normalize whitespace and simple cleaning\n",
    "def normalize_text(t: str) -> str:\n",
    "    t = re.sub(r'\\s+', ' ', t).strip()\n",
    "    return t\n",
    "\n",
    "norm_pairs = []\n",
    "seen = set()\n",
    "for u, r, src in all_samples:\n",
    "    u2 = normalize_text(u)\n",
    "    r2 = normalize_text(r)\n",
    "    key = (u2.lower(), r2.lower())\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    norm_pairs.append((u2, r2, src))\n",
    "\n",
    "print(\"After dedupe:\", len(norm_pairs))\n",
    "\n",
    "random.shuffle(norm_pairs)\n",
    "\n",
    "# Optionally expand until target size (MB) by repeating with small paraphrase variations\n",
    "if TARGET_SIZE_MB is not None:\n",
    "    target_bytes = int(TARGET_SIZE_MB * 1024 * 1024)\n",
    "    est = 0\n",
    "    out_lines = []\n",
    "    idx = 0\n",
    "    # small paraphrase function: randomly swap templates for same source\n",
    "    def paraphrase_reply(reply):\n",
    "        # naive: just return reply (you can add simple synonyms or template variations here)\n",
    "        return reply\n",
    "    while est < target_bytes:\n",
    "        u, r, s = norm_pairs[idx % len(norm_pairs)]\n",
    "        r2 = paraphrase_reply(r)\n",
    "        sample = f\"USER: {u}\\nCOMPATIKA: {r2}\\n\\n\"\n",
    "        out_lines.append(sample)\n",
    "        est += len(sample.encode(\"utf-8\"))\n",
    "        idx += 1\n",
    "    print(f\"Expanded to {len(out_lines)} lines to reach ~{TARGET_SIZE_MB} MB\")\n",
    "    Path(output_txt).write_text(\"\".join(out_lines), encoding=\"utf-8\")\n",
    "else:\n",
    "    # write all normalized pairs to TXT\n",
    "    with open(output_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        for u, r, s in norm_pairs:\n",
    "            f.write(f\"USER: {u}\\nCOMPATIKA: {r}\\n\\n\")\n",
    "    print(f\"Wrote {len(norm_pairs)} samples to {output_txt} (size: {os.path.getsize(output_txt)/(1024*1024):.2f} MB)\")\n",
    "\n",
    "# ========== Done ==========\n",
    "print(\"Done. Sample output preview:\")\n",
    "with open(output_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    preview = \"\".join([next(f) for _ in range(20)]) if os.path.getsize(output_txt)>0 else \"\"\n",
    "print(preview)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327e3869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
